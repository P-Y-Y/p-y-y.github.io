---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# Hi, I am Yuyang Peng (ÂΩ≠Èõ®Ê¥ã). #

At present, I am working with Professor Yao Wan at HUST.

My research interests are deeply rooted in the latest advancements in generative models, especially multimodal.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2025 Workshop</div><img src='images/livevqa0.jpg' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LIVEVQA: Assessing Models with Live Visual Knowledge](https://openreview.net/pdf?id=sLFrSp7xNs)

Mingyang Fu, **Yuyang Peng**, Benlin Liu, Yao Wan, Dongping Chen

</div>
</div>

# üéñ Honors and Awards
- Silver Medal, ACM-ICPC Asia Shenyang Regional Contest (2024)
- Bronze Medal, National Olympiad in Informatics (NOI) (2021)

# üìñ Educations
- *2023.09 - 2027.06(expected)*, CS(Turing), Huazhong University of Science and Technology. 

